{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaseen2402/ADS/blob/main/hackSubmit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSom4EoFOgDL"
      },
      "source": [
        "# Template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZx8H1YmOgDL"
      },
      "source": [
        "**For demo purposes, this Notebook Template will use the [Social Circle dataset from SNAP](https://snap.stanford.edu/data/ego-Facebook.html) to provide a walk-through of the expected Hackathon Submission for attendees.**\n",
        "\n",
        "This facebook network is undirected and has no weights because one user can become friends with another user just once. Looking at the dataset from a graph analysis perspective:\n",
        "- Each node represents an anonymized facebook user that belongs to one of those ten friends lists.\n",
        "- Each edge corresponds to the friendship of two facebook users that belong to this network. In other words, two users must become friends on facebook in order for them to be connected in the particular network.\n",
        "\n",
        "**Note that this dataset is not permitted to be used for submission purposes, it is only meant to be shown as an example.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4nmLCFf3HoC",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Step 0: Package Installation & setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV0dx8Ny1q64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb88554-1768-42a8-84fa-c26f7e9adc8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nx-arangodb in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: networkx<=3.4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (3.4)\n",
            "Requirement already satisfied: phenolrs~=0.5 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (0.5.9)\n",
            "Requirement already satisfied: python-arango~=8.1 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (8.1.5)\n",
            "Requirement already satisfied: adbnx-adapter~=5.0.5 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (5.0.6)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (2.32.3)\n",
            "Requirement already satisfied: rich>=12.5.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (13.9.4)\n",
            "Requirement already satisfied: setuptools>=45 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (75.1.0)\n",
            "Requirement already satisfied: numpy~=1.26 in /usr/local/lib/python3.11/dist-packages (from phenolrs~=0.5->nx-arangodb) (1.26.4)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (2.3.0)\n",
            "Requirement already satisfied: requests_toolbelt in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (1.0.0)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (2.10.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (8.6.1)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (24.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.7.1->python-arango~=8.1->nx-arangodb) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# 1. Install nx-arangodb via pip\n",
        "# Github: https://github.com/arangodb/nx-arangodb\n",
        "\n",
        "!pip install nx-arangodb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIAJV8R2OgDN",
        "outputId": "39c6534c-d16b-4bae-9389-0f95f3f69f53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb 25 10:24:19 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "# 2. Check if you have an NVIDIA GPU\n",
        "# Note: If this returns \"command not found\", then GPU-based algorithms via cuGraph are unavailable\n",
        "\n",
        "!nvidia-smi\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d4UkcR0OgDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed4eba3a-c17d-4df9-a9fd-105ecac18f1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Requirement already satisfied: nx-cugraph-cu12 in /usr/local/lib/python3.11/dist-packages (24.12.0)\n",
            "Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (13.3.0)\n",
            "Requirement already satisfied: networkx>=3.2 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (3.4)\n",
            "Requirement already satisfied: numpy<3.0a0,>=1.23 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (1.26.4)\n",
            "Requirement already satisfied: pylibcugraph-cu12==24.12.* in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (24.12.0)\n",
            "Requirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.5.3.2)\n",
            "Requirement already satisfied: nvidia-curand-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (10.3.6.82)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (11.6.3.83)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.5.1.3)\n",
            "Requirement already satisfied: pylibraft-cu12==24.12.* in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (24.12.0)\n",
            "Requirement already satisfied: rmm-cu12==24.12.* in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (24.12.1)\n",
            "Requirement already satisfied: cuda-python<13.0a0,<=12.6.0,>=12.0 in /usr/local/lib/python3.11/dist-packages (from pylibraft-cu12==24.12.*->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.6.0)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.11/dist-packages (from rmm-cu12==24.12.*->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (0.61.0)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x>=12.0.0->nx-cugraph-cu12) (0.8.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.5.82)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57->rmm-cu12==24.12.*->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (0.44.0)\n"
          ]
        }
      ],
      "source": [
        "# 3. Install nx-cugraph via pip\n",
        "# Note: Only enable this installation if the step above is working!\n",
        "\n",
        "!pip install nx-cugraph-cu12 --extra-index-url https://pypi.nvidia.com # Requires CUDA-capable GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qsN6QZ4OgDO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db665983-8dfa-4541-e97c-805ae627bf85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.74-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.37)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Collecting langchain-core<1.0.0,>=0.3.35 (from langchain)\n",
            "  Downloading langchain_core-0.3.39-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.61.1)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.16-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.53-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.7-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.2.74-py3-none-any.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.4/151.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_core-0.3.39-py3-none-any.whl (414 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.1/414.1 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.16-py3-none-any.whl (38 kB)\n",
            "Downloading langgraph_sdk-0.1.53-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.0-py3-none-any.whl (30 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, typing-inspect, tiktoken, pydantic-settings, langgraph-sdk, dataclasses-json, langchain-core, langgraph-checkpoint, langchain-openai, langgraph, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.37\n",
            "    Uninstalling langchain-core-0.3.37:\n",
            "      Successfully uninstalled langchain-core-0.3.37\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.3.18 langchain-core-0.3.39 langchain-openai-0.3.7 langgraph-0.2.74 langgraph-checkpoint-2.0.16 langgraph-sdk-0.1.53 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.0 python-dotenv-1.0.1 tiktoken-0.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# 4. Install LangChain & LangGraph\n",
        "\n",
        "!pip install --upgrade langchain langchain-community langchain-openai langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_-6k16xOgDO",
        "outputId": "81743d8c-d916-41b3-d3c1-af04421a76cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[10:24:55 +0000] [INFO]: NetworkX-cuGraph is available.\n",
            "INFO:nx_arangodb:NetworkX-cuGraph is available.\n"
          ]
        }
      ],
      "source": [
        "# 5. Import the required modules\n",
        "\n",
        "import networkx as nx\n",
        "import nx_arangodb as nxadb\n",
        "\n",
        "from arango import ArangoClient\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import re\n",
        "\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.graphs import ArangoGraph\n",
        "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
        "from langchain_core.tools import tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGD0DX_qOgDO",
        "outputId": "75f6553a-f39d-4feb-ac84-f9e9d826fb13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<StandardDatabase _system>\n"
          ]
        }
      ],
      "source": [
        "# 6. Connect to the ArangoDB database\n",
        "# TODO: Configure your credentials here!\n",
        "\n",
        "db = ArangoClient(hosts=\"https://9bbcec363899.arangodb.cloud:8529\").db(username=\"root\", password=\"Tz4qxdb6XopV5TQ9BJtc\", verify=True)\n",
        "\n",
        "print(db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "-TFGCBjYOgDP"
      },
      "source": [
        "### Step 1: Choose & prepare your dataset for NetworkX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4Z49YDXOgDP"
      },
      "source": [
        "This section will provide a template for data transformation, including placeholders for loading CSV/JSON files, defining graph schemas, and preparing data for ingestion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oObXUMcYOgDP",
        "outputId": "6a29a616-223c-4dc4-da01-6f4a2405e7ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-24 10:46:43--  https://snap.stanford.edu/data/ERC20-stablecoins.zip\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2967555937 (2.8G) [application/zip]\n",
            "Saving to: ‘ERC20-stablecoins.zip.1’\n",
            "\n",
            "ERC20-stablecoins.z 100%[===================>]   2.76G  45.1MB/s    in 67s     \n",
            "\n",
            "2025-02-24 10:47:51 (42.5 MB/s) - ‘ERC20-stablecoins.zip.1’ saved [2967555937/2967555937]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Download the dataset\n",
        "# Reference: https://snap.stanford.edu/data/ego-Facebook.html\n",
        "# Reference: https://networkx.org/nx-guides/content/exploratory_notebooks/facebook_notebook.html#facebook-network-analysis\n",
        "\n",
        "!wget https://snap.stanford.edu/data/ERC20-stablecoins.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfx5vaqx2bWl",
        "outputId": "81d181cd-57b7-4957-b258-65cf3488346e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './ERC20-stablecoins.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1b6fe65c7e2b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Extract the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ERC20-stablecoins.zip'"
          ]
        }
      ],
      "source": [
        "# 2. Load the dataset into a CSV\n",
        "# Reference: https://networkx.org/nx-guides/content/exploratory_notebooks/facebook_notebook.html#analysis\n",
        "# Reference: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
        "\n",
        "import zipfile\n",
        "\n",
        "zip_path = \"./ERC20-stablecoins.zip\"\n",
        "extract_path = \"./stablecoins_data\"\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extraction complete. Files:\", zip_ref.namelist())\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "csv_path = \"./stablecoins_data/token_transfers_V3.0.0.csv\"  # Adjust based on extracted filenames\n",
        "\n",
        "# Read the CSV\n",
        "stablecoins = pd.read_csv(csv_path, nrows=100000)\n",
        "\n",
        "# Display first few rows\n",
        "print(stablecoins.head())\n",
        "\n",
        "# import pandas as pd\n",
        "# stablecoins = pd.read_csv(\n",
        "#     \"./ERC20-stablecoins.zip\",\n",
        "#     compression=\"gzip\",\n",
        "#     sep=\" \",\n",
        "#     names=[\"start_node\", \"end_node\"],\n",
        "# )\n",
        "\n",
        "# stablecoins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "rXjrv2RSOgDQ"
      },
      "source": [
        "### Step 2: Convert and Load Graph Data into NetworkX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPB2JAQhOgDR"
      },
      "source": [
        "This section will include placeholders for defining graph nodes, edges, and visualizing small test datasets before full ingestion.\n",
        "\n",
        "Although we are creating a NetworkX Graph from a Pandas Edgelist in this example, there many other ways you can load data into NetworkX.\n",
        "\n",
        "For more information about this, refer to the following documentation: https://networkx.org/documentation/stable/reference/convert.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnGqBwYO49Kq"
      },
      "outputs": [],
      "source": [
        "# 1. Load the dataset a NetworkX Graph\n",
        "# Reference: https://networkx.org/documentation/stable/reference/generated/networkx.convert_matrix.from_pandas_edgelist.html\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "# Create a directed graph (since transactions have direction)\n",
        "G = nx.from_pandas_edgelist(stablecoins, \"from_address\", \"to_address\",\n",
        "                            edge_attr=[\"value\", \"time_stamp\"],\n",
        "                            create_using=nx.DiGraph)\n",
        "\n",
        "print(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hq2Az38xOgDS",
        "outputId": "11d65f13-c354-4793-f3fc-b025f85b5b30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NetworkXError",
          "evalue": "nbunch is not a node or a sequence of nodes.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36mbunch_iter\u001b[0;34m(nlist, adj)\u001b[0m\n\u001b[1;32m   2039\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2041\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNetworkXError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-71843da66ea5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 2. Print the degree of one of the nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m107\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/classes/reportviews.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, nbunch, weight)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbunch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/classes/reportviews.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, G, nbunch, weight)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_succ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_succ\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_succ\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pred\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_pred\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_succ\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnbunch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbunch_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbunch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36mbunch_iter\u001b[0;34m(nlist, adj)\u001b[0m\n\u001b[1;32m   2053\u001b[0m                             \u001b[0;34mf\"Node {n} in sequence nbunch is not a valid node.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m                         )\n\u001b[0;32m-> 2055\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0mbunch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbunch_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbunch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNetworkXError\u001b[0m: nbunch is not a node or a sequence of nodes."
          ]
        }
      ],
      "source": [
        "# 2. Print the degree of one of the nodes\n",
        "\n",
        "print(G.degree(107))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K72E_Y8SOgDS"
      },
      "outputs": [],
      "source": [
        "# 3. Visualize the Graph\n",
        "# Reference: https://networkx.org/nx-guides/content/exploratory_notebooks/facebook_notebook.html#visualizing-the-graph\n",
        "pos = nx.spring_layout(G, k=0.2, iterations=10, seed=42)\n",
        "\n",
        "plot_options = {\n",
        "    \"node_size\": 5,          # Smaller nodes\n",
        "    \"with_labels\": False,     # No labels for readability\n",
        "    \"edge_color\": \"gray\",     # Light gray edges\n",
        "    \"alpha\": 0.6,             # Slight transparency\n",
        "    \"width\": 0.1              # Thin edges\n",
        "}\n",
        "\n",
        "# Plot the graph\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "nx.draw_networkx(G, pos=pos, ax=ax, **plot_options)\n",
        "\n",
        "plt.title(\"Stablecoin Transactions Network (Subset)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "vkfkKybAOgDT"
      },
      "source": [
        "### Step 3: Persist the Graph in ArangoDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfjtT5_VOgDT"
      },
      "source": [
        "This section will include pre-written code templates for interacting with ArangoDB, making it easier for participants to insert and query their data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN3q_1z8OgDT"
      },
      "source": [
        "For this new [nxadb.Graph()](https://nx-arangodb.readthedocs.io/en/latest/classes/graph.html) object, we will pass `name=\"Facebook\"`, `db=db`, and `incoming_graph_data=G_nx`. This last parameter allows us to load the NetworkX Graph directly into ArangoDB:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDOUGn1iOgDT"
      },
      "outputs": [],
      "source": [
        "# 1. Load the NetworkX Graph into ArangoDB\n",
        "# Reference: https://github.com/arangodb/nx-arangodb?tab=readme-ov-file#can-i-create-an-arangodb-graph-from-an-existing-networkx-graph\n",
        "\n",
        "G_adb = nxadb.Graph(\n",
        "    name=\"stablecoins\",\n",
        "    db=db,\n",
        "    incoming_graph_data=G,\n",
        "    write_batch_size=50000 # feel free to modify\n",
        ")\n",
        "\n",
        "print(G_adb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgk7jS3cOgDU"
      },
      "source": [
        "Great! We've created our first [nxadb.Graph()](https://nx-arangodb.readthedocs.io/en/latest/classes/graph.html) object.\n",
        "\n",
        "Note that there are [4 Graph Types](https://networkx.org/documentation/stable/reference/classes/index.html) in NetworkX, which are also supported as [nxadb Graphs](https://nx-arangodb.readthedocs.io/en/latest/classes/index.html):\n",
        "\n",
        "1. `nxadb.Graph`: This class implements an undirected graph. It ignores multiple edges between two nodes. It does allow self-loop edges between a node and itself.\n",
        "2. `nxadb.DiGraph`: Directed graphs, that is, graphs with directed edges. Provides operations common to directed graphs, (a subclass of Graph).\n",
        "3. `nxadb.MultiGraph`: A flexible graph class that allows multiple undirected edges between pairs of nodes. The additional flexibility leads to some degradation in performance, though usually not significant.\n",
        "4. `nxadb.MultiDiGraph`: A directed version of a MultiGraph.\n",
        "\n",
        "Let's continue with the same Graph for now, and re-instantiate the `G_adb` object to showcase the persistence factor!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3ThlpALI5G9",
        "outputId": "5b3bfdf5-1db8-4159-c7ee-600822cac106",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[10:25:24 +0000] [INFO]: Graph 'stablecoins' exists.\n",
            "INFO:nx_arangodb:Graph 'stablecoins' exists.\n",
            "[10:25:24 +0000] [INFO]: Default node type set to 'stablecoins_node'\n",
            "INFO:nx_arangodb:Default node type set to 'stablecoins_node'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph named 'stablecoins' with 58873 nodes and 78147 edges\n"
          ]
        }
      ],
      "source": [
        "# 2. Re-connect to the same Graph\n",
        "\n",
        "G_adb = nxadb.Graph(name=\"stablecoins\", db=db)\n",
        "\n",
        "print(G_adb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpZOytbNOgDV"
      },
      "source": [
        "Feel free to take a moment to view the created graph in ArangoDB:\n",
        "\n",
        "1. Log into your deployment with username `root` and your designated password.\n",
        "2. Select your database (most likely `_system`)\n",
        "3. Navigate to the `GRAPHS` tab (selectable on the left-hand side after login)\n",
        "4. Click on your graph (in this example, it would be called `Facebook`)\n",
        "5. Experiment with the visualizer options to learn more about your Graph\n",
        "\n",
        "For example, here's a quick sample of our `Facebook` graph:\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"attachment:54d53cbe-c3b4-407a-9acf-b141c561f14f.png\" style=\"height: 400px;\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44g4lDdfOgDW",
        "outputId": "764f5691-48ba-4f07-cbe8-cdb0cbd21037"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1045"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 3. Print the degree of a Node\n",
        "\n",
        "G_adb.degree(107)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS6UclK3OgDX",
        "outputId": "20bf1ab0-fc87-49d4-ac27-ef80608b7c02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'_key': '27024', '_id': 'stablecoins_node/27024', '_rev': '_jRc6YCi-_-'}, {'_key': '13481', '_id': 'stablecoins_node/13481', '_rev': '_jRc6Xx2--8'}, {'_key': '3822', '_id': 'stablecoins_node/3822', '_rev': '_jRc6XrO-AS'}]\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "# 4. Query the Graph\n",
        "# Reference: https://arangodb.com/sql-aql-comparison/\n",
        "\n",
        "# Sample 3 nodes\n",
        "result = G_adb.query(\"\"\"\n",
        "    FOR node IN stablecoins_node\n",
        "        SORT RAND()\n",
        "        LIMIT 3\n",
        "        RETURN node\n",
        "\"\"\")\n",
        "\n",
        "print(list(result))\n",
        "print('-'*10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyT_HIlsOgDX"
      },
      "source": [
        "Final note: Heterogeneous Graphs in NetworkX aren't \"officially\" distinguished from Homogenous NetworkX Graphs. NetworkX **does not** provide a structured way to distinguish between different Node Types or Edge Types. It is up to the NetworKX user to define *how* they want to make this distinction.\n",
        "\n",
        "In the case of NetworkX-ArangoDB, we choose to support Heteregeneous Graphs via the `_id` field, which allows us to specify the **ArangoDB Collection** associated to the Node or Edge.\n",
        "\n",
        "However, if the NetworkX Graph is homogenous, we can choose interact with its Nodes and Edges **with or without** specifying the ArangoDB Collection as part of the ID.\n",
        "\n",
        "Here is an example of what we mean:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bL_fwOpt5zzA",
        "outputId": "73b1151f-f927-4a3b-eff5-2682bd812620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'_key': '1', '_id': 'Facebook_node/1'}\n",
            "{'_key': '1', '_id': 'Facebook_node/1'}\n",
            "{'_key': '1', '_id': 'Facebook_node/1'}\n",
            "----\n",
            "{'_from': 'Facebook_node/0', '_id': 'Facebook_node_to_Facebook_node/0', '_key': '0', '_to': 'Facebook_node/1'}\n",
            "{'_from': 'Facebook_node/0', '_id': 'Facebook_node_to_Facebook_node/0', '_key': '0', '_to': 'Facebook_node/1'}\n",
            "{'_from': 'Facebook_node/0', '_id': 'Facebook_node_to_Facebook_node/0', '_key': '0', '_to': 'Facebook_node/1'}\n"
          ]
        }
      ],
      "source": [
        "# 5. Experimenting with different node keys\n",
        "\n",
        "print(G_adb.nodes[1])\n",
        "print(G_adb.nodes[\"1\"])\n",
        "print(G_adb.nodes[\"Facebook_node/1\"])\n",
        "\n",
        "print('----')\n",
        "\n",
        "print(G_adb[0][1])\n",
        "print(G_adb[\"0\"][1])\n",
        "print(G_adb[\"Facebook_node/0\"][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "5Gy3_0cCOgDY"
      },
      "source": [
        "### Step 4: Build the Agentic App with LangChain & LangGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcWopcDzOgDY"
      },
      "source": [
        "This section will provide pre-built agent templates, guiding participants on how to dynamically select AQL vs. NetworkX/cuGraph execution paths based on user input.\n",
        "\n",
        "Reference:\n",
        "- https://www.langchain.com/\n",
        "- https://www.langchain.com/langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JNpXWwfOgDY"
      },
      "outputs": [],
      "source": [
        "# 1. Create the ArangoGraph LangChain wrapper\n",
        "# Reference: https://api.python.langchain.com/en/latest/graphs/langchain_community.graphs.arangodb_graph.ArangoGraph.html\n",
        "\n",
        "arango_graph = ArangoGraph(db)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai langchain-google-genai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6EOBw9CmHlG",
        "outputId": "a53428bc-afac-4ce9-9c7d-cfd4363a093e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.0.10)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.10.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.37 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.39)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.67.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.3.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.27.2)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy0RM6abOgDZ",
        "outputId": "0d59b2aa-c335-4bd1-ea85-8505ebd50297",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am doing well, thank you for asking!  How are you today?\n"
          ]
        }
      ],
      "source": [
        "# 2. Define the llm object\n",
        "# Note: You can use any llm you want. We will be using OpenAI for example purposes.\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyB_1xpdJwxr409IPtqtpBFUr561ZWEaNCk\"\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
        "\n",
        "# Test the model\n",
        "response = llm.invoke(\"Hello! How are you?\")\n",
        "print(response.content)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool"
      ],
      "metadata": {
        "id": "c6EQsmRXoBKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVCJ0oRaOgDZ"
      },
      "outputs": [],
      "source": [
        "# 3. Define an example LangGraph Tool\n",
        "# Note: This is not actually required for the Hackathon submission. This is just meant as a soft introduction to creating Tools in LangGraph\n",
        "\n",
        "@tool\n",
        "def favourite_fruit(query: str)->str:\n",
        "    \"\"\"You are responsible for responding to being asked what your favourite fruit is.\n",
        "    You must say Avocado!\n",
        "    \"\"\"\n",
        "    return \"Avocado!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B04yCiTZOgDZ"
      },
      "outputs": [],
      "source": [
        "# 4. Define the Text to AQL Tool\n",
        "# Reference: https://python.langchain.com/docs/integrations/graphs/arangodb/\n",
        "# Reference: https://python.langchain.com/api_reference/community/chains/langchain_community.chains.graph_qa.arangodb.ArangoGraphQAChain.html\n",
        "# Note: It is encouraged to experiment and improve this section! This is just a placeholder:\n",
        "\n",
        "@tool\n",
        "def text_to_aql_to_text(query: str)->str:\n",
        "    \"\"\"This tool is available to invoke the\n",
        "    ArangoGraphQAChain object, which enables you to\n",
        "    translate a Natural Language Query into AQL, execute\n",
        "    the query, and translate the result back into Natural Language.\n",
        "    \"\"\"\n",
        "\n",
        "    llm = ChatGoogleGenerativeAI(temperature=0, model=\"gemini-1.5-flash\")\n",
        "\n",
        "    chain = ArangoGraphQAChain.from_llm(\n",
        "    \tllm=llm,\n",
        "    \tgraph=arango_graph,\n",
        "    \tverbose=True,\n",
        "        allow_dangerous_requests=True\n",
        "    )\n",
        "\n",
        "    result = chain.invoke(query)\n",
        "\n",
        "    return str(result[\"result\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwfh9V9oOgDa"
      },
      "outputs": [],
      "source": [
        "# 5. Define the Text to NetworkX/cuGraph Tool\n",
        "# Note: It is encouraged to experiment and improve this section! This is just a placeholder:\n",
        "\n",
        "@tool\n",
        "def text_to_nx_algorithm_to_text(query: str)->str:\n",
        "    \"\"\"This tool is available to invoke a NetworkX Algorithm on\n",
        "    the ArangoDB Graph. You are responsible for accepting the\n",
        "    Natural Language Query, establishing which algorithm needs to\n",
        "    be executed, executing the algorithm, and translating the results back\n",
        "    to Natural Language, with respect to the original query.\n",
        "\n",
        "    If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use\n",
        "    this tool.\n",
        "    \"\"\"\n",
        "\n",
        "    llm = ChatGoogleGenerativeAI(temperature=0, model=\"gemini-1.5-flash\")\n",
        "\n",
        "    ######################\n",
        "    print(\"1) Generating NetworkX code\")\n",
        "\n",
        "    text_to_nx = llm.invoke(f\"\"\"\n",
        "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "    I have the following graph analysis query: {query}.\n",
        "\n",
        "    Generate the Python Code required to answer the query using the `G_adb` object.\n",
        "\n",
        "    Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n",
        "\n",
        "    Only assume that networkx is installed, and other base python dependencies.\n",
        "\n",
        "    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
        "\n",
        "    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
        "\n",
        "    Make sure that `FINAL_RESULT` stores a short & consice answer. Avoid setting this variable to a long sequence.\n",
        "\n",
        "    Your code:\n",
        "    \"\"\").content\n",
        "\n",
        "    text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n",
        "\n",
        "    print('-'*10)\n",
        "    print(text_to_nx_cleaned)\n",
        "    print('-'*10)\n",
        "\n",
        "    ######################\n",
        "\n",
        "    print(\"\\n2) Executing NetworkX code\")\n",
        "    global_vars = {\"G_adb\": G_adb, \"nx\": nx}\n",
        "    local_vars = {}\n",
        "\n",
        "    try:\n",
        "        exec(text_to_nx_cleaned, global_vars, local_vars)\n",
        "        text_to_nx_final = text_to_nx\n",
        "    except Exception as e:\n",
        "        print(f\"EXEC ERROR: {e}\")\n",
        "        return f\"EXEC ERROR: {e}\"\n",
        "\n",
        "        # TODO: Consider experimenting with a code corrector!\n",
        "        attempt = 1\n",
        "        MAX_ATTEMPTS = 3\n",
        "\n",
        "        # while attempt <= MAX_ATTEMPTS\n",
        "            # ...\n",
        "\n",
        "    print('-'*10)\n",
        "    FINAL_RESULT = local_vars[\"FINAL_RESULT\"]\n",
        "    print(f\"FINAL_RESULT: {FINAL_RESULT}\")\n",
        "    print('-'*10)\n",
        "\n",
        "    ######################\n",
        "\n",
        "    print(\"3) Formulating final answer\")\n",
        "\n",
        "    nx_to_text = llm.invoke(f\"\"\"\n",
        "        I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "        I have the following graph analysis query: {query}.\n",
        "\n",
        "        I have executed the following python code to help me answer my query:\n",
        "\n",
        "        ---\n",
        "        {text_to_nx_final}\n",
        "        ---\n",
        "\n",
        "        The `FINAL_RESULT` variable is set to the following: {FINAL_RESULT}.\n",
        "\n",
        "        Based on my original Query and FINAL_RESULT, generate a short and concise response to\n",
        "        answer my query.\n",
        "\n",
        "        Your response:\n",
        "    \"\"\").content\n",
        "\n",
        "    return nx_to_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZSFDHKeOgDa"
      },
      "outputs": [],
      "source": [
        "# 6. Create the Agentic Application\n",
        "\n",
        "# Note: Consider implementing a hybrid tool that combines both AQL & NetworkX Algorithms!\n",
        "\n",
        "tools = [text_to_aql_to_text, text_to_nx_algorithm_to_text, favourite_fruit]\n",
        "\n",
        "def query_graph(query):\n",
        "    llm = ChatGoogleGenerativeAI(temperature=0, model=\"gemini-1.5-flash\")\n",
        "    app = create_react_agent(llm, tools)\n",
        "    final_state = app.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
        "    return final_state[\"messages\"][-1].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYa6R5dkOgDa"
      },
      "outputs": [],
      "source": [
        "# 7. Experiment with example queries\n",
        "# Note: Some may work, some may not!\n",
        "\n",
        "query = \"What is your favourite fruit?\"\n",
        "query = \"Are there isolated nodes?\"\n",
        "query = \"Which node has the highest betweenness centrality score? Use a k value of 10\"\n",
        "query = \"Who is connected to Node 0?\"\n",
        "query = \"What is the shortest path from Node 0 to Node 1?\"\n",
        "query = \"Update node 0 to have attribute foo=bar\"\n",
        "query = \"Is the graph fully connected?\"\n",
        "query = \"What is the average degree of nodes?\"\n",
        "query = \"Are there nodes that, if removed, would fragment the network?\"\n",
        "query = \"Which users are outliers in terms of connections?\"\n",
        "query = \"Which nodes are the most connected?\"\n",
        "query = \"How strongly connected is the network? Used connected components\"\n",
        "query = \"Fetch the highest pagerank node and value\"\n",
        "query = \"Who is the most influential node?\"\n",
        "query = \"Who is the most popular person in the Graph? Explain why\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYUoYWAmOgDb",
        "outputId": "9d78c232-700e-49b1-91b6-60720db57363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"This request requires graph data which is not available in the current context.  To answer this question, I need access to a graph database and the ability to query it for popularity metrics (e.g., number of connections, centrality measures).  The available tools don't provide this functionality.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "query_graph(\"Who is the most popular person in the Graph? Explain why\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwkOVEH3OgDb",
        "outputId": "8065ba83-b330-49e3-97a6-58bce1622ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
            "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
            "WITH stablecoins_node, stablecoins_node_to_stablecoins_node\n",
            "FOR v, e IN 1..1 OUTBOUND 'stablecoins_node/0' stablecoins_node_to_stablecoins_node\n",
            "RETURN {vertex: v, edge: e}\n",
            "\u001b[0m\n",
            "AQL Result:\n",
            "\u001b[32;1m\u001b[1;3m[{'vertex': {'_key': '1', '_id': 'stablecoins_node/1', '_rev': '_jRc6Xp2--_'}, 'edge': {'_key': '0', '_id': 'stablecoins_node_to_stablecoins_node/0', '_from': 'stablecoins_node/0', '_to': 'stablecoins_node/1', '_rev': '_jRc6Y2y---', 'value': 800, 'time_stamp': 1648811421}}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Node 0 is connected to Node 1.  The connection has a value of 800 and a timestamp of 1648811421.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "query_graph(\"Who is connected to Node 0?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujZl-uy8OgDb",
        "outputId": "a6dd2603-ebc0-4129-9cdc-4b92f8371eef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) Generating NetworkX code\n",
            "----------\n",
            "import networkx as nx\n",
            "\n",
            "# Sample G_adb graph (replace with your actual G_adb graph)\n",
            "G_adb = nx.Graph()\n",
            "G_adb.add_edge('stablecoins_node/0', 'stablecoins_node/1', value=800, time_stamp=1648811421)\n",
            "\n",
            "\n",
            "try:\n",
            "    shortest_path = nx.shortest_path(G_adb, source='stablecoins_node/0', target='stablecoins_node/1')\n",
            "    FINAL_RESULT = shortest_path\n",
            "except nx.NetworkXNoPath:\n",
            "    FINAL_RESULT = \"No path found\"\n",
            "----------\n",
            "\n",
            "2) Executing NetworkX code\n",
            "----------\n",
            "FINAL_RESULT: ['stablecoins_node/0', 'stablecoins_node/1']\n",
            "----------\n",
            "3) Formulating final answer\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The shortest path from Node 0 to Node 1 is: Node 0, Node 1.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "query_graph(\"What is the shortest path from Node 0 to Node 1?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsuAtwO1OgDc",
        "outputId": "948ef19f-945e-4ced-bc75-11f4d7934549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) Generating NetworkX code\n",
            "----------\n",
            "import networkx as nx\n",
            "\n",
            "# Assuming G_adb is already defined and loaded.  Replace this with your actual loading code if needed.\n",
            "# Example (replace with your actual loading):\n",
            "# G_adb = nx.read_graphml(\"your_graph.graphml\")\n",
            "\n",
            "\n",
            "# 1. Identify connected components using NetworkX's connected_components algorithm.\n",
            "connected_components = list(nx.connected_components(G_adb))\n",
            "\n",
            "# 2. Calculate the size of the largest connected component. This represents the strongest connected part of the network.\n",
            "largest_component_size = max(len(component) for component in connected_components)\n",
            "\n",
            "# 3. Calculate the ratio of the largest component to the total number of nodes. This gives a measure of how strongly connected the overall network is.  A ratio closer to 1 indicates a strongly connected network.\n",
            "total_nodes = len(G_adb.nodes)\n",
            "connectivity_ratio = largest_component_size / total_nodes if total_nodes > 0 else 0\n",
            "\n",
            "\n",
            "# 4.  Provide a concise answer based on the connectivity ratio.  Adjust thresholds as needed for your application.\n",
            "if connectivity_ratio > 0.9:\n",
            "    FINAL_RESULT = \"Highly connected\"\n",
            "elif connectivity_ratio > 0.5:\n",
            "    FINAL_RESULT = \"Moderately connected\"\n",
            "else:\n",
            "    FINAL_RESULT = \"Weakly connected\"\n",
            "----------\n",
            "\n",
            "2) Executing NetworkX code\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[10:32:43 +0000] [INFO]: Graph 'stablecoins' load took 1.3841450214385986s\n",
            "INFO:nx_arangodb:Graph 'stablecoins' load took 1.3841450214385986s\n",
            "[10:32:46 +0000] [INFO]: NXCG Graph construction took 2.549943685531616s\n",
            "INFO:nx_arangodb:NXCG Graph construction took 2.549943685531616s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "FINAL_RESULT: Moderately connected\n",
            "----------\n",
            "3) Formulating final answer\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The network is moderately connected, with the largest connected component comprising more than half of the total nodes.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "query_graph(\"How strongly connected is the network? Used connected components\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llFUuW7MOgDc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8f4eaf2-c482-40ef-a7e1-3f1dbaccf32b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.18.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.2 (from gradio)\n",
            "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.18.0-py3-none-any.whl (62.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 fastapi-0.115.8 ffmpy-0.5.0 gradio-5.18.0 gradio-client-1.7.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.7 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "markupsafe"
                ]
              },
              "id": "d43ceee3e7a540e6a811ca27709f12eb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 8. (Optional) Set up UI via Gradio\n",
        "\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMRjDo_QOgDc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "outputId": "8bd79246-0464-4725-a018-cd25e64fb9b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://337e28422e96721083.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://337e28422e96721083.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "gr.Interface(fn=query_graph, inputs=\"text\", outputs=\"text\").launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nITsaGN2OgDd"
      },
      "source": [
        "### Wrap-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvE72VsCOgDd"
      },
      "source": [
        "This concludes the Hackathon Notebook Template. You are free to re-use any section provided in this notebook for your selected dataset. You are encouraged to experiment and to break things! We want to use this opportunity to grow our existing open source packages you've seen here, and gauge interest from the community.\n",
        "\n",
        "Happy hacking!\n",
        "\n",
        "- The ArangoDB Team"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8SEwhPoOgDd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "L4nmLCFf3HoC",
        "hoyxgmOz3CwF",
        "vrB4FpB63yEF",
        "5fsZEyyh3F87",
        "VE6lCtDb6KGw"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}